{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://imgur.com/3U3hI1u.png\" width=\"100%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boas vindas a sua segunda e última tarefa de Aprendizado por Reforço!\n",
    "\n",
    "Neste exercício, você deverá implementar e comparar diferentes algoritmos de **Aprendizado por Reforço Profundo** utilizando a biblioteca _[Stable Baselines 3](https://stable-baselines3.readthedocs.io/en/master/)_.\n",
    "\n",
    "A _Stable Baselines_ é uma biblioteca de Aprendizado por Reforço que implementa diversos algoritmos de agentes, além de várias funcionalidades úteis para seu treinamento. Suas implementações são bem simples e intuitivas, mas sem deixarem de ser otimizadas e poderosas, buscando facilitar o desenvolvimento de projetos de reforço de alta qualidade.\n",
    "\n",
    "Antes de começar a tarefa, é importante acessar e se familiarizar com o tutorial da biblioteca disponível neste repositório! Depois de rodar o guia, você já estará capaz de completar este trabalho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolha do Ambiente\n",
    "\n",
    "Antes de analisar o possíveis algoritmos, o primeiro passo é escolher qual ambiente você quer resolver! Para esta tarefa, separamos dois possíveis ambientes diferentes, em ordem de dificuldade, que você poderá escolher: **CartPole** e **Pendulum**. Lembrando que, quanto mais difícil um ambiente, mais demorado será o treinamento.\n",
    "\n",
    "A seguir, estão as descrições de cada um deles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">CartPole</h2>\n",
    "<img src=\"https://bytepawn.com/images/cartpole.gif\" width=50% />\n",
    "\n",
    "**CartPole** é o ambiente de Aprendizado por Reforço mais comum do Gym, no qual deve-se balancear um pêndulo invertido conectado a um carrinho, somente controlando os movimentos do carrinho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Características do Ambiente\n",
    "\n",
    "O **Espaço de Observação** do CartPole é definido por 4 informações:\n",
    "\n",
    "<br>\n",
    "\n",
    "|     | Informação                         | Min     | Max    |\n",
    "| :-- | :--------------------------------- | :-----: | :----: |\n",
    "| 0   | Posição do Carrinho                | -4.8    | 4.8    |\n",
    "| 1   | Velocidade do Carrinho             | -Inf    | Inf    |\n",
    "| 2   | Ângulo da Barra                    | -24 deg | 24 deg |\n",
    "| 3   | Velocidade na Extremidade da Barra | -Inf    | Inf    |\n",
    "\n",
    "<br>\n",
    "\n",
    "A posição do carrinho vai de -4.8 a 4.8, mas ele perde o episódio caso saia dos limites de -2.4 e 2.4. Da mesma forma, o ângulo da barra vai de -24° a 24°, porém o episódio acaba caso a barra saia dos limites de -12° e 12°.\n",
    "\n",
    "Já o **Espaço de Ação** é composto por duas ações únicas: mover o carrinho para a **esquerda** ou para a **direita**.\n",
    "\n",
    "Quando queremos mover o carrinho para a esquerda, fazemos um `env.step(0)`; quando queremos movê-lo para a direita, enviamos um `env.step(1)`\n",
    "\n",
    "| Ação | Significado           |\n",
    "| :--- | :-------------------- |\n",
    "| 0    | Mover para a esquerda |\n",
    "| 1    | Mover para a direito  |\n",
    "\n",
    "Por fim, cada vez que tomamos uma ação, recebemos do ambiente uma **recompensa**, que é igual a +1 para cada instante que passa sem o agente perder. Assim, o CartPole é incentivado a sobreviver por mais tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testar o modelo, vamos precisar de 2 bibliotecas: **gym** (para inicialização dos ambientes) e **stable_baselines3** (para inicialização e avaliação dos modelos):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Recompensa Média: 8.60 +/- 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caste\\Envs\\main\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gym \n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Definindo ambiente\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# Definindo modelo\n",
    "model = PPO(\"MlpPolicy\", env, seed=1, verbose=1)\n",
    "\n",
    "# Avaliando o agente\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=5, deterministic=True)\n",
    "\n",
    "print(f\"Recompensa Média: {mean_reward:.2f} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Pendulum</h2>\n",
    "\n",
    "<img src=\"https://www.gymlibrary.dev/_images/pendulum.gif\" width=30% />\n",
    "\n",
    "**Pendulum** é um ambiente do Gym que simula um pêndulo pendurado por um ponto tentando se balancear de cabeça para baixo. O agente deve um torque no pêndulo de forma que ele se levante e fique parado em pé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Características do Ambiente\n",
    "\n",
    "O **Espaço de Observação** do ambiente é definido por 8 informações.\n",
    "\n",
    "| Estado    | Informação                                     |\n",
    "| :-------- | :--------------------------------------------- |\n",
    "| 0         | Posição no eixo _x_ da ponta do pêndulo        |\n",
    "| 1         | Posição no eixo _y_ da ponta do pêndulo        |\n",
    "| 2         | Velocidade angular do pêndulo                  |\n",
    "\n",
    "Já o **Espaço de Ação** é um espaço **contínuo** do torque aplicado no pêndulo.\n",
    "\n",
    "| Ação | Significado     | Intervalo   |\n",
    "| :--- | :-------------- | :---------- |\n",
    "| 0    | Torque          | $-2$ a $+2$ |\n",
    "\n",
    "Por fim, cada vez que tomamos uma ação, recebemos do ambiente uma **recompensa**, que segue a seguinte equação:\n",
    "\n",
    "$$r = -(\\theta{}^2 + 0.1 * \\dot{\\theta}^2 + 0.001 * \\tau{})$$\n",
    "\n",
    "Desta forma, temos que a recompensa é menor quando o ângulo do pêndulo é menor (mais em pé), quando a velocidade angular é baixa, e quando usamos pouco torque.\n",
    "\n",
    "Por ser um ambiente com espaço de ação contínuo, os algoritmos que podemos usar serão diferentes, e o treinamento pode ser mais demorado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ambiente\n",
    "\n",
    "Para criar o ambiente, basta rodar a linha de código a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Pendulum-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1 - Testando Modelos\n",
    "\n",
    "Caro piloto, agora que você conhece esses dois ambientes, é hora de brincar com eles. Você deverá testar diferentes algoritmos (a seu critério), e ver sua recompensa média. Para ver quais as limitações dos modelos, veja esse [link](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html). Abaixo, criamos uma função que será útil para comparar os modelos posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValues(model, env, n_episodes, info_dict):\n",
    "    model_name = str(model.__class__).split(\".\")[-1][:-2]\n",
    "\n",
    "    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=n_episodes, deterministic=True)\n",
    "    \n",
    "    info_dict[model_name] = {}\n",
    "    info_dict[model_name][\"mean_reward\"] = mean_reward\n",
    "    info_dict[model_name][\"std_reward\"] = std_reward\n",
    "    \n",
    "    return info_dict\n",
    "\n",
    "algorithms_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando e Avaliando seu próprio modelo\n",
    "\n",
    "Primeiramente, agora você deve decidir em qual ambiente você deseja treinar seu agente. Para isto, basta tirar o comentário da linha referente ao ambiente escolhido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_name = \"CartPole-v1\"\n",
    "env_name = \"Pendulum-v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, você está livre para testar diferentes algoritmos para seu ambiente!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o ambiente escolhido foi o `Pendulum-v1`, usaremos apenas algoritmos que suportem espaços de ações contínuos, o que é equivalente a: `action_space = Box`. Além disso, como trabalharei com Single Process, testarei os algoritmos indicados [aqui](https://stable-baselines.readthedocs.io/en/master/guide/rl_tips.html), ou seja, `TD3` e `SAC`. Por fim, vou implementar alguns modelos usando tais algoritmos e comparar os resultados encontrados com o resultado obtido para um modelo com hiperparâmetros já tunados, disponíveis no [RL zoo](https://github.com/DLR-RM/rl-baselines3-zoo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.45e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 3137      |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 800       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.38e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 3361      |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 1600      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.28e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 3560      |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 2400      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.34e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 3563      |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 3200      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.3e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 3693     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 4000     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.29e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 3806      |\n",
      "|    time_elapsed    | 1         |\n",
      "|    total_timesteps | 4800      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.29e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 3856      |\n",
      "|    time_elapsed    | 1         |\n",
      "|    total_timesteps | 5600      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.26e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 3909      |\n",
      "|    time_elapsed    | 1         |\n",
      "|    total_timesteps | 6400      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.24e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 36        |\n",
      "|    fps             | 3964      |\n",
      "|    time_elapsed    | 1         |\n",
      "|    total_timesteps | 7200      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.24e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 40        |\n",
      "|    fps             | 3980      |\n",
      "|    time_elapsed    | 2         |\n",
      "|    total_timesteps | 8000      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.23e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 44        |\n",
      "|    fps             | 4012      |\n",
      "|    time_elapsed    | 2         |\n",
      "|    total_timesteps | 8800      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.24e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 48        |\n",
      "|    fps             | 4037      |\n",
      "|    time_elapsed    | 2         |\n",
      "|    total_timesteps | 9600      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.25e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 52        |\n",
      "|    fps             | 1947      |\n",
      "|    time_elapsed    | 5         |\n",
      "|    total_timesteps | 10400     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 7.57      |\n",
      "|    critic_loss     | 5.1       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 200       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.27e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 56        |\n",
      "|    fps             | 652       |\n",
      "|    time_elapsed    | 17        |\n",
      "|    total_timesteps | 11200     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 17.5      |\n",
      "|    critic_loss     | 0.0566    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 1000      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.27e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 60        |\n",
      "|    fps             | 379       |\n",
      "|    time_elapsed    | 31        |\n",
      "|    total_timesteps | 12000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 27.7      |\n",
      "|    critic_loss     | 0.0839    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 1800      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.27e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 64        |\n",
      "|    fps             | 269       |\n",
      "|    time_elapsed    | 47        |\n",
      "|    total_timesteps | 12800     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 37.2      |\n",
      "|    critic_loss     | 0.16      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 2600      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.27e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 68        |\n",
      "|    fps             | 220       |\n",
      "|    time_elapsed    | 61        |\n",
      "|    total_timesteps | 13600     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 46.7      |\n",
      "|    critic_loss     | 0.265     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 3400      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.25e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 72        |\n",
      "|    fps             | 188       |\n",
      "|    time_elapsed    | 76        |\n",
      "|    total_timesteps | 14400     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 54.7      |\n",
      "|    critic_loss     | 0.331     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 4200      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.19e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 76        |\n",
      "|    fps             | 163       |\n",
      "|    time_elapsed    | 93        |\n",
      "|    total_timesteps | 15200     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 59.7      |\n",
      "|    critic_loss     | 0.42      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 5000      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.16e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 80        |\n",
      "|    fps             | 147       |\n",
      "|    time_elapsed    | 108       |\n",
      "|    total_timesteps | 16000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 64.9      |\n",
      "|    critic_loss     | 0.519     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 5800      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.11e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 84        |\n",
      "|    fps             | 136       |\n",
      "|    time_elapsed    | 122       |\n",
      "|    total_timesteps | 16800     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 68.3      |\n",
      "|    critic_loss     | 0.655     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 6600      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.07e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 88        |\n",
      "|    fps             | 128       |\n",
      "|    time_elapsed    | 137       |\n",
      "|    total_timesteps | 17600     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 69.5      |\n",
      "|    critic_loss     | 0.744     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 7400      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.03e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 92        |\n",
      "|    fps             | 122       |\n",
      "|    time_elapsed    | 150       |\n",
      "|    total_timesteps | 18400     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 71.2      |\n",
      "|    critic_loss     | 1.03      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 8200      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -990     |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 117      |\n",
      "|    time_elapsed    | 163      |\n",
      "|    total_timesteps | 19200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 72.3     |\n",
      "|    critic_loss     | 1.27     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9000     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -958     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 112      |\n",
      "|    time_elapsed    | 177      |\n",
      "|    total_timesteps | 20000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 72.6     |\n",
      "|    critic_loss     | 1.46     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9800     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Modelo de TD3 que usa hiperparâmetros já tunados do RL zoo\n",
    "from stable_baselines3 import TD3 # Importe o modelo do stable_baselines3\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "import numpy as np\n",
    "\n",
    "# Definindo o ambiente\n",
    "env = gym.make(env_name)\n",
    "\n",
    "policy_kwargs = {'net_arch':[400,300]}\n",
    "action_noise = NormalActionNoise(np.zeros(1), 0.1*np.ones(1))\n",
    "model = TD3(policy='MlpPolicy', env=env, seed=1, verbose=1, buffer_size=int(2e5), learning_starts=int(1e4), gamma=0.98, policy_kwargs=policy_kwargs,\n",
    "            action_noise=action_noise) # Defina o modelo\n",
    "model.learn(total_timesteps= 2e4) # Treine o modelo\n",
    "n_episodes = 20 # Defina o número de episódios\n",
    "\n",
    "# Avaliando o agente e guardando o desempenho no dicionário\n",
    "algorithms_dict = getValues(model, env, n_episodes, algorithms_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.57e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 54        |\n",
      "|    time_elapsed    | 14        |\n",
      "|    total_timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 28.1      |\n",
      "|    critic_loss     | 0.0398    |\n",
      "|    ent_coef        | 0.5       |\n",
      "|    ent_coef_loss   | -1.09     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 699       |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.5e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 1600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 53.1     |\n",
      "|    critic_loss     | 0.0462   |\n",
      "|    ent_coef        | 0.263    |\n",
      "|    ent_coef_loss   | -1.16    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.3e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 53       |\n",
      "|    total_timesteps | 2400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 69.5     |\n",
      "|    critic_loss     | 0.163    |\n",
      "|    ent_coef        | 0.208    |\n",
      "|    ent_coef_loss   | -0.00906 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2299     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.15e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 43        |\n",
      "|    time_elapsed    | 73        |\n",
      "|    total_timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 78.8      |\n",
      "|    critic_loss     | 0.388     |\n",
      "|    ent_coef        | 0.227     |\n",
      "|    ent_coef_loss   | 0.248     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 3099      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -963     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 92       |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 82.9     |\n",
      "|    critic_loss     | 0.574    |\n",
      "|    ent_coef        | 0.245    |\n",
      "|    ent_coef_loss   | 0.00745  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -828     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 4800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 80.7     |\n",
      "|    critic_loss     | 0.726    |\n",
      "|    ent_coef        | 0.203    |\n",
      "|    ent_coef_loss   | 0.00814  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -727     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 133      |\n",
      "|    total_timesteps | 5600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 85.5     |\n",
      "|    critic_loss     | 1.64     |\n",
      "|    ent_coef        | 0.169    |\n",
      "|    ent_coef_loss   | 0.0569   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -691     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 153      |\n",
      "|    total_timesteps | 6400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 83.8     |\n",
      "|    critic_loss     | 1.29     |\n",
      "|    ent_coef        | 0.149    |\n",
      "|    ent_coef_loss   | -0.0213  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -625     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 173      |\n",
      "|    total_timesteps | 7200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 87.8     |\n",
      "|    critic_loss     | 4.51     |\n",
      "|    ent_coef        | 0.135    |\n",
      "|    ent_coef_loss   | 0.0365   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -574     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 193      |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 76.7     |\n",
      "|    critic_loss     | 1.76     |\n",
      "|    ent_coef        | 0.122    |\n",
      "|    ent_coef_loss   | 0.143    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -536     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 213      |\n",
      "|    total_timesteps | 8800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 75.8     |\n",
      "|    critic_loss     | 1.52     |\n",
      "|    ent_coef        | 0.117    |\n",
      "|    ent_coef_loss   | -0.227   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -504     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 234      |\n",
      "|    total_timesteps | 9600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 73.4     |\n",
      "|    critic_loss     | 2.17     |\n",
      "|    ent_coef        | 0.107    |\n",
      "|    ent_coef_loss   | -0.0181  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -472     |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 256      |\n",
      "|    total_timesteps | 10400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 71.1     |\n",
      "|    critic_loss     | 1.98     |\n",
      "|    ent_coef        | 0.111    |\n",
      "|    ent_coef_loss   | -0.0351  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 10299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -450     |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 280      |\n",
      "|    total_timesteps | 11200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 59       |\n",
      "|    critic_loss     | 2.83     |\n",
      "|    ent_coef        | 0.103    |\n",
      "|    ent_coef_loss   | -0.0995  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 11099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -428     |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 301      |\n",
      "|    total_timesteps | 12000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 54.1     |\n",
      "|    critic_loss     | 2.17     |\n",
      "|    ent_coef        | 0.0962   |\n",
      "|    ent_coef_loss   | -0.0693  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 11899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -413     |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 321      |\n",
      "|    total_timesteps | 12800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 59.1     |\n",
      "|    critic_loss     | 2.88     |\n",
      "|    ent_coef        | 0.0827   |\n",
      "|    ent_coef_loss   | -0.249   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 12699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -397     |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 341      |\n",
      "|    total_timesteps | 13600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 52       |\n",
      "|    critic_loss     | 1.34     |\n",
      "|    ent_coef        | 0.0697   |\n",
      "|    ent_coef_loss   | -0.656   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 13499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -387     |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 361      |\n",
      "|    total_timesteps | 14400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 53.4     |\n",
      "|    critic_loss     | 1.35     |\n",
      "|    ent_coef        | 0.0607   |\n",
      "|    ent_coef_loss   | 0.0127   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 14299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -375     |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 380      |\n",
      "|    total_timesteps | 15200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 47.9     |\n",
      "|    critic_loss     | 1.46     |\n",
      "|    ent_coef        | 0.0516   |\n",
      "|    ent_coef_loss   | -0.223   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 15099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -367     |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 400      |\n",
      "|    total_timesteps | 16000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 51.6     |\n",
      "|    critic_loss     | 1.18     |\n",
      "|    ent_coef        | 0.05     |\n",
      "|    ent_coef_loss   | 0.658    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 15899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -359     |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 420      |\n",
      "|    total_timesteps | 16800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 48.2     |\n",
      "|    critic_loss     | 2.32     |\n",
      "|    ent_coef        | 0.0458   |\n",
      "|    ent_coef_loss   | 0.404    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 16699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -348     |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 440      |\n",
      "|    total_timesteps | 17600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 43.9     |\n",
      "|    critic_loss     | 1.06     |\n",
      "|    ent_coef        | 0.0371   |\n",
      "|    ent_coef_loss   | -0.377   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 17499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -340     |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 459      |\n",
      "|    total_timesteps | 18400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 46.8     |\n",
      "|    critic_loss     | 1.22     |\n",
      "|    ent_coef        | 0.033    |\n",
      "|    ent_coef_loss   | -0.0637  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 18299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -330     |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 479      |\n",
      "|    total_timesteps | 19200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 35.5     |\n",
      "|    critic_loss     | 1.08     |\n",
      "|    ent_coef        | 0.0312   |\n",
      "|    ent_coef_loss   | -0.871   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 19099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -324     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 499      |\n",
      "|    total_timesteps | 20000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 42.9     |\n",
      "|    critic_loss     | 1.07     |\n",
      "|    ent_coef        | 0.026    |\n",
      "|    ent_coef_loss   | -0.115   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 19899    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caste\\Envs\\main\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Modelo de SAC que usa hiperparâmetros já tunados do RL zoo\n",
    "from stable_baselines3 import SAC # Importe o modelo do stable_baselines3\n",
    "\n",
    "model = SAC(policy='MlpPolicy', env=env, seed=1, verbose=1, learning_rate=1e-3) # Defina o modelo\n",
    "model.learn(total_timesteps= 2e4) # Treine o modelo\n",
    "n_episodes = 20 # Defina o número de episódios\n",
    "\n",
    "# Avaliando o agente e guardando o desempenho no dicionário\n",
    "algorithms_dict = getValues(model, env, n_episodes, algorithms_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TD3 ideal': {'mean_reward': -147.04256373576936,\n",
       "  'std_reward': 114.15893494822676},\n",
       " 'SAC ideal': {'mean_reward': -137.0330131453462,\n",
       "  'std_reward': 98.30879141029631}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resultado dos modelos com hiperparâmetros tunados\n",
    "algorithms_dict = dict(zip(['TD3 ideal', 'SAC ideal'], list(algorithms_dict.values())))\n",
    "algorithms_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos os resultados ótimos, vou formular alguns modelos, tanto do `TD3` quanto do `SAC`, variando apenas alguns hiperparâmetros e deixando os outros com seu valor default, por fim, considerarei, apenas, o modelo com maior recompensa média. Os hiperparâmetros que irei variar para ambos algoritmos são:\n",
    "- `gama`;\n",
    "- `learning_rate`;\n",
    "- `action_noise`(apenas para o `TD3`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.58e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 95        |\n",
      "|    time_elapsed    | 8         |\n",
      "|    total_timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 15.2      |\n",
      "|    critic_loss     | 0.295     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 600       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.55e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 78        |\n",
      "|    time_elapsed    | 20        |\n",
      "|    total_timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 26.1      |\n",
      "|    critic_loss     | 0.0979    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 1400      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.51e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 71        |\n",
      "|    time_elapsed    | 33        |\n",
      "|    total_timesteps | 2400      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 36.6      |\n",
      "|    critic_loss     | 0.177     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 2200      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.45e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 68        |\n",
      "|    time_elapsed    | 46        |\n",
      "|    total_timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 45.5      |\n",
      "|    critic_loss     | 0.147     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3000      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.36e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 67        |\n",
      "|    time_elapsed    | 59        |\n",
      "|    total_timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 52.2      |\n",
      "|    critic_loss     | 0.194     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3800      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.3e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 66       |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 4800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 55.8     |\n",
      "|    critic_loss     | 0.377    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4600     |\n",
      "---------------------------------\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.56e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 97        |\n",
      "|    time_elapsed    | 8         |\n",
      "|    total_timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 15.5      |\n",
      "|    critic_loss     | 0.133     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 600       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.54e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 75        |\n",
      "|    time_elapsed    | 21        |\n",
      "|    total_timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 26.6      |\n",
      "|    critic_loss     | 0.0847    |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 1400      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.43e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 69        |\n",
      "|    time_elapsed    | 34        |\n",
      "|    total_timesteps | 2400      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 35.7      |\n",
      "|    critic_loss     | 0.166     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 2200      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.34e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 67        |\n",
      "|    time_elapsed    | 47        |\n",
      "|    total_timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 42.9      |\n",
      "|    critic_loss     | 0.244     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 3000      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.2e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 65       |\n",
      "|    time_elapsed    | 61       |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 45.9     |\n",
      "|    critic_loss     | 0.314    |\n",
      "|    learning_rate   | 0.0006   |\n",
      "|    n_updates       | 3800     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.14e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 64        |\n",
      "|    time_elapsed    | 74        |\n",
      "|    total_timesteps | 4800      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 48.9      |\n",
      "|    critic_loss     | 0.416     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 4600      |\n",
      "----------------------------------\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.58e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 97        |\n",
      "|    time_elapsed    | 8         |\n",
      "|    total_timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 14.7      |\n",
      "|    critic_loss     | 0.29      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 600       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.55e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 20        |\n",
      "|    total_timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 24.1      |\n",
      "|    critic_loss     | 0.0887    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 1400      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.5e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 71       |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 2400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 32.3     |\n",
      "|    critic_loss     | 0.126    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2200     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.45e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 69        |\n",
      "|    time_elapsed    | 46        |\n",
      "|    total_timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 38.5      |\n",
      "|    critic_loss     | 0.113     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3000      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.38e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 67        |\n",
      "|    time_elapsed    | 59        |\n",
      "|    total_timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 42.4      |\n",
      "|    critic_loss     | 0.533     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3800      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.33e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 66        |\n",
      "|    time_elapsed    | 72        |\n",
      "|    total_timesteps | 4800      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 44.6      |\n",
      "|    critic_loss     | 0.195     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 4600      |\n",
      "----------------------------------\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.56e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 96        |\n",
      "|    time_elapsed    | 8         |\n",
      "|    total_timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 14.9      |\n",
      "|    critic_loss     | 0.128     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 600       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.54e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 75        |\n",
      "|    time_elapsed    | 21        |\n",
      "|    total_timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 24.5      |\n",
      "|    critic_loss     | 0.0709    |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 1400      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.47e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 70        |\n",
      "|    time_elapsed    | 34        |\n",
      "|    total_timesteps | 2400      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 32.3      |\n",
      "|    critic_loss     | 0.116     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 2200      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.42e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 67        |\n",
      "|    time_elapsed    | 47        |\n",
      "|    total_timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 38.2      |\n",
      "|    critic_loss     | 0.143     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 3000      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.32e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 65        |\n",
      "|    time_elapsed    | 61        |\n",
      "|    total_timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 40.5      |\n",
      "|    critic_loss     | 0.221     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 3800      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.22e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 64        |\n",
      "|    time_elapsed    | 74        |\n",
      "|    total_timesteps | 4800      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 40.6      |\n",
      "|    critic_loss     | 0.202     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 4600      |\n",
      "----------------------------------\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.55e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 95        |\n",
      "|    time_elapsed    | 8         |\n",
      "|    total_timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 14.3      |\n",
      "|    critic_loss     | 0.211     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 600       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.52e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 20        |\n",
      "|    total_timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 25.5      |\n",
      "|    critic_loss     | 0.0662    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 1400      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.45e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 70        |\n",
      "|    time_elapsed    | 33        |\n",
      "|    total_timesteps | 2400      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 36        |\n",
      "|    critic_loss     | 0.1       |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 2200      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.42e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 68        |\n",
      "|    time_elapsed    | 46        |\n",
      "|    total_timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 45        |\n",
      "|    critic_loss     | 0.101     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3000      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.31e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 67        |\n",
      "|    time_elapsed    | 59        |\n",
      "|    total_timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 50        |\n",
      "|    critic_loss     | 0.17      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3800      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.31e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 66        |\n",
      "|    time_elapsed    | 72        |\n",
      "|    total_timesteps | 4800      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 56.3      |\n",
      "|    critic_loss     | 0.47      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 4600      |\n",
      "----------------------------------\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.56e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 97        |\n",
      "|    time_elapsed    | 8         |\n",
      "|    total_timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 15.6      |\n",
      "|    critic_loss     | 0.165     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 600       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.52e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 20        |\n",
      "|    total_timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 26.4      |\n",
      "|    critic_loss     | 0.0731    |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 1400      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.21e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 70        |\n",
      "|    time_elapsed    | 34        |\n",
      "|    total_timesteps | 2400      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 30.6      |\n",
      "|    critic_loss     | 0.117     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 2200      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.22e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 67        |\n",
      "|    time_elapsed    | 47        |\n",
      "|    total_timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 38.6      |\n",
      "|    critic_loss     | 0.236     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 3000      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.18e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 65        |\n",
      "|    time_elapsed    | 60        |\n",
      "|    total_timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 44.8      |\n",
      "|    critic_loss     | 0.389     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 3800      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.17e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 64        |\n",
      "|    time_elapsed    | 74        |\n",
      "|    total_timesteps | 4800      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 49.5      |\n",
      "|    critic_loss     | 0.491     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 4600      |\n",
      "----------------------------------\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.55e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 96        |\n",
      "|    time_elapsed    | 8         |\n",
      "|    total_timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 13.9      |\n",
      "|    critic_loss     | 0.209     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 600       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.52e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 77        |\n",
      "|    time_elapsed    | 20        |\n",
      "|    total_timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 23.5      |\n",
      "|    critic_loss     | 0.066     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 1400      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.33e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 71        |\n",
      "|    time_elapsed    | 33        |\n",
      "|    total_timesteps | 2400      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 28.6      |\n",
      "|    critic_loss     | 0.0703    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 2200      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.32e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 68        |\n",
      "|    time_elapsed    | 46        |\n",
      "|    total_timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 35.4      |\n",
      "|    critic_loss     | 0.0705    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3000      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.22e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 67        |\n",
      "|    time_elapsed    | 59        |\n",
      "|    total_timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 38.6      |\n",
      "|    critic_loss     | 0.0955    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3800      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.23e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 66        |\n",
      "|    time_elapsed    | 71        |\n",
      "|    total_timesteps | 4800      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 41.5      |\n",
      "|    critic_loss     | 0.154     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 4600      |\n",
      "----------------------------------\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.48e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 96        |\n",
      "|    time_elapsed    | 8         |\n",
      "|    total_timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 14.1      |\n",
      "|    critic_loss     | 0.202     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 600       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.49e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 20        |\n",
      "|    total_timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 23.6      |\n",
      "|    critic_loss     | 0.0715    |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 1400      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.32e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 70        |\n",
      "|    time_elapsed    | 34        |\n",
      "|    total_timesteps | 2400      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 29.2      |\n",
      "|    critic_loss     | 0.112     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 2200      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.3e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 67       |\n",
      "|    time_elapsed    | 47       |\n",
      "|    total_timesteps | 3200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 35.1     |\n",
      "|    critic_loss     | 0.123    |\n",
      "|    learning_rate   | 0.0006   |\n",
      "|    n_updates       | 3000     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.18e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 65        |\n",
      "|    time_elapsed    | 60        |\n",
      "|    total_timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 37.4      |\n",
      "|    critic_loss     | 0.166     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 3800      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.13e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 64        |\n",
      "|    time_elapsed    | 74        |\n",
      "|    total_timesteps | 4800      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 38        |\n",
      "|    critic_loss     | 0.174     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 4600      |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Modelos de TD3\n",
    "action_noise = [NormalActionNoise(np.zeros(1), 0.1*np.ones(1)), None]\n",
    "gamma = [0.95, 0.9]\n",
    "learning_rate = [3e-4, 6e-4,]\n",
    "max_mean_reward = float('-inf')\n",
    "\n",
    "for ac in action_noise:\n",
    "    for g in gamma:\n",
    "        for lr in learning_rate:\n",
    "            model = TD3(policy='MlpPolicy', env=env, seed=1, verbose=1, learning_rate=lr, gamma=g, action_noise=ac) # Defina o modelo\n",
    "            model.learn(total_timesteps= 5e3) # Treine o modelo\n",
    "            n_episodes = 20 # Defina o número de episódios\n",
    "            # Avaliando o agente e guardando o desempenho no dicionário\n",
    "            mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=n_episodes, deterministic=True)\n",
    "            if mean_reward > max_mean_reward:\n",
    "                max_mean_reward = mean_reward\n",
    "                max_std_reward = std_reward\n",
    "                opt_gamma = g\n",
    "                opt_lr = lr\n",
    "                opt_ac = ac\n",
    "\n",
    "algorithms_dict['TD3 teste'] = {'mean_reward': max_mean_reward, 'std_reward': max_std_reward}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado\n",
      "action_noise obtido: None\n",
      "gamma obtido: 0.9\n",
      "learning_rate obtido: 0.0006\n"
     ]
    }
   ],
   "source": [
    "print('Melhor conjunto de hiperparâmetros encontrado para o TD3\\naction_noise obtido: ' + str(opt_ac))\n",
    "print(f'gamma obtido: {opt_gamma}')\n",
    "print(f'learning_rate obtido: {opt_lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.52e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 48        |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 24.1      |\n",
      "|    critic_loss     | 0.2       |\n",
      "|    ent_coef        | 0.812     |\n",
      "|    ent_coef_loss   | -0.338    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 699       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.54e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 44        |\n",
      "|    time_elapsed    | 36        |\n",
      "|    total_timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 45.7      |\n",
      "|    critic_loss     | 0.0983    |\n",
      "|    ent_coef        | 0.643     |\n",
      "|    ent_coef_loss   | -0.691    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 1499      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.4e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 54       |\n",
      "|    total_timesteps | 2400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 56.8     |\n",
      "|    critic_loss     | 0.193    |\n",
      "|    ent_coef        | 0.522    |\n",
      "|    ent_coef_loss   | -0.822   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2299     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.26e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 43        |\n",
      "|    time_elapsed    | 73        |\n",
      "|    total_timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 62.6      |\n",
      "|    critic_loss     | 0.205     |\n",
      "|    ent_coef        | 0.436     |\n",
      "|    ent_coef_loss   | -0.688    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3099      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.13e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 42        |\n",
      "|    time_elapsed    | 93        |\n",
      "|    total_timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 65.2      |\n",
      "|    critic_loss     | 0.199     |\n",
      "|    ent_coef        | 0.37      |\n",
      "|    ent_coef_loss   | -0.6      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3899      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -993     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 4800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 62.4     |\n",
      "|    critic_loss     | 0.177    |\n",
      "|    ent_coef        | 0.319    |\n",
      "|    ent_coef_loss   | -0.528   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -879     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 131      |\n",
      "|    total_timesteps | 5600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 64.5     |\n",
      "|    critic_loss     | 0.295    |\n",
      "|    ent_coef        | 0.273    |\n",
      "|    ent_coef_loss   | -0.29    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -785     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 151      |\n",
      "|    total_timesteps | 6400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 56       |\n",
      "|    critic_loss     | 0.288    |\n",
      "|    ent_coef        | 0.232    |\n",
      "|    ent_coef_loss   | -0.639   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -708     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 171      |\n",
      "|    total_timesteps | 7200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 58       |\n",
      "|    critic_loss     | 0.219    |\n",
      "|    ent_coef        | 0.196    |\n",
      "|    ent_coef_loss   | -0.408   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -650     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 190      |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 52.1     |\n",
      "|    critic_loss     | 0.126    |\n",
      "|    ent_coef        | 0.164    |\n",
      "|    ent_coef_loss   | -0.414   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -605     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 210      |\n",
      "|    total_timesteps | 8800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 48.4     |\n",
      "|    critic_loss     | 0.117    |\n",
      "|    ent_coef        | 0.135    |\n",
      "|    ent_coef_loss   | -0.815   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -568     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 229      |\n",
      "|    total_timesteps | 9600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 44.4     |\n",
      "|    critic_loss     | 0.173    |\n",
      "|    ent_coef        | 0.113    |\n",
      "|    ent_coef_loss   | -0.329   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9499     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caste\\Envs\\main\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.55e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 25.5      |\n",
      "|    critic_loss     | 0.0885    |\n",
      "|    ent_coef        | 0.659     |\n",
      "|    ent_coef_loss   | -0.673    |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 699       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.52e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 44        |\n",
      "|    time_elapsed    | 35        |\n",
      "|    total_timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 46.3      |\n",
      "|    critic_loss     | 0.0592    |\n",
      "|    ent_coef        | 0.423     |\n",
      "|    ent_coef_loss   | -1.13     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 1499      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.35e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 42        |\n",
      "|    time_elapsed    | 55        |\n",
      "|    total_timesteps | 2400      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 56.7      |\n",
      "|    critic_loss     | 0.0892    |\n",
      "|    ent_coef        | 0.305     |\n",
      "|    ent_coef_loss   | -0.85     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 2299      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.19e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 42        |\n",
      "|    time_elapsed    | 75        |\n",
      "|    total_timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 59.8      |\n",
      "|    critic_loss     | 0.144     |\n",
      "|    ent_coef        | 0.242     |\n",
      "|    ent_coef_loss   | -0.346    |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 3099      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.03e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 41        |\n",
      "|    time_elapsed    | 96        |\n",
      "|    total_timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 59.3      |\n",
      "|    critic_loss     | 0.172     |\n",
      "|    ent_coef        | 0.2       |\n",
      "|    ent_coef_loss   | -0.306    |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 3899      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -890     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 116      |\n",
      "|    total_timesteps | 4800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 57.8     |\n",
      "|    critic_loss     | 0.163    |\n",
      "|    ent_coef        | 0.169    |\n",
      "|    ent_coef_loss   | -0.4     |\n",
      "|    learning_rate   | 0.0006   |\n",
      "|    n_updates       | 4699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -781     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 136      |\n",
      "|    total_timesteps | 5600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 55.3     |\n",
      "|    critic_loss     | 0.255    |\n",
      "|    ent_coef        | 0.142    |\n",
      "|    ent_coef_loss   | 0.156    |\n",
      "|    learning_rate   | 0.0006   |\n",
      "|    n_updates       | 5499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -699     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 157      |\n",
      "|    total_timesteps | 6400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 50.8     |\n",
      "|    critic_loss     | 0.348    |\n",
      "|    ent_coef        | 0.123    |\n",
      "|    ent_coef_loss   | -0.495   |\n",
      "|    learning_rate   | 0.0006   |\n",
      "|    n_updates       | 6299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -632     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 177      |\n",
      "|    total_timesteps | 7200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 52.1     |\n",
      "|    critic_loss     | 0.373    |\n",
      "|    ent_coef        | 0.105    |\n",
      "|    ent_coef_loss   | 0.155    |\n",
      "|    learning_rate   | 0.0006   |\n",
      "|    n_updates       | 7099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -581     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 197      |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 46       |\n",
      "|    critic_loss     | 0.189    |\n",
      "|    ent_coef        | 0.0873   |\n",
      "|    ent_coef_loss   | 0.0917   |\n",
      "|    learning_rate   | 0.0006   |\n",
      "|    n_updates       | 7899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -542     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 217      |\n",
      "|    total_timesteps | 8800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 42.4     |\n",
      "|    critic_loss     | 0.162    |\n",
      "|    ent_coef        | 0.0723   |\n",
      "|    ent_coef_loss   | -0.124   |\n",
      "|    learning_rate   | 0.0006   |\n",
      "|    n_updates       | 8699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -511     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 237      |\n",
      "|    total_timesteps | 9600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 40.3     |\n",
      "|    critic_loss     | 0.171    |\n",
      "|    ent_coef        | 0.0625   |\n",
      "|    ent_coef_loss   | -0.365   |\n",
      "|    learning_rate   | 0.0006   |\n",
      "|    n_updates       | 9499     |\n",
      "---------------------------------\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.52e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 50        |\n",
      "|    time_elapsed    | 15        |\n",
      "|    total_timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 22.2      |\n",
      "|    critic_loss     | 0.187     |\n",
      "|    ent_coef        | 0.812     |\n",
      "|    ent_coef_loss   | -0.34     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 699       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.53e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 45        |\n",
      "|    time_elapsed    | 35        |\n",
      "|    total_timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 38.6      |\n",
      "|    critic_loss     | 0.0739    |\n",
      "|    ent_coef        | 0.641     |\n",
      "|    ent_coef_loss   | -0.708    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 1499      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.38e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 43        |\n",
      "|    time_elapsed    | 54        |\n",
      "|    total_timesteps | 2400      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 44.9      |\n",
      "|    critic_loss     | 0.0802    |\n",
      "|    ent_coef        | 0.515     |\n",
      "|    ent_coef_loss   | -0.912    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 2299      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.26e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 42        |\n",
      "|    time_elapsed    | 74        |\n",
      "|    total_timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 44.6      |\n",
      "|    critic_loss     | 0.07      |\n",
      "|    ent_coef        | 0.421     |\n",
      "|    ent_coef_loss   | -0.884    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3099      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.12e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 42        |\n",
      "|    time_elapsed    | 93        |\n",
      "|    total_timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 45.2      |\n",
      "|    critic_loss     | 0.0523    |\n",
      "|    ent_coef        | 0.348     |\n",
      "|    ent_coef_loss   | -0.806    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3899      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -998     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 4800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 40.8     |\n",
      "|    critic_loss     | 0.0641   |\n",
      "|    ent_coef        | 0.289    |\n",
      "|    ent_coef_loss   | -0.907   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -883     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 133      |\n",
      "|    total_timesteps | 5600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 42.9     |\n",
      "|    critic_loss     | 0.0545   |\n",
      "|    ent_coef        | 0.24     |\n",
      "|    ent_coef_loss   | -0.897   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -792     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 152      |\n",
      "|    total_timesteps | 6400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 35       |\n",
      "|    critic_loss     | 0.0479   |\n",
      "|    ent_coef        | 0.197    |\n",
      "|    ent_coef_loss   | -1.1     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -715     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 172      |\n",
      "|    total_timesteps | 7200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 37       |\n",
      "|    critic_loss     | 0.0378   |\n",
      "|    ent_coef        | 0.161    |\n",
      "|    ent_coef_loss   | -0.89    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -657     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 191      |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 31       |\n",
      "|    critic_loss     | 0.0423   |\n",
      "|    ent_coef        | 0.131    |\n",
      "|    ent_coef_loss   | -0.825   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -611     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 211      |\n",
      "|    total_timesteps | 8800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 28.2     |\n",
      "|    critic_loss     | 0.0371   |\n",
      "|    ent_coef        | 0.106    |\n",
      "|    ent_coef_loss   | -1.3     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -575     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 230      |\n",
      "|    total_timesteps | 9600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 28.3     |\n",
      "|    critic_loss     | 0.0278   |\n",
      "|    ent_coef        | 0.0858   |\n",
      "|    ent_coef_loss   | -0.98    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9499     |\n",
      "---------------------------------\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.54e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 23.5      |\n",
      "|    critic_loss     | 0.0773    |\n",
      "|    ent_coef        | 0.658     |\n",
      "|    ent_coef_loss   | -0.681    |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 699       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.52e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 44        |\n",
      "|    time_elapsed    | 36        |\n",
      "|    total_timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 39.2      |\n",
      "|    critic_loss     | 0.0291    |\n",
      "|    ent_coef        | 0.419     |\n",
      "|    ent_coef_loss   | -1.26     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 1499      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.35e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 42        |\n",
      "|    time_elapsed    | 56        |\n",
      "|    total_timesteps | 2400      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 44.8      |\n",
      "|    critic_loss     | 0.0452    |\n",
      "|    ent_coef        | 0.291     |\n",
      "|    ent_coef_loss   | -1.04     |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 2299      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.23e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 42        |\n",
      "|    time_elapsed    | 76        |\n",
      "|    total_timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 46.6      |\n",
      "|    critic_loss     | 0.062     |\n",
      "|    ent_coef        | 0.219     |\n",
      "|    ent_coef_loss   | -0.718    |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 3099      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.08e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 41        |\n",
      "|    time_elapsed    | 96        |\n",
      "|    total_timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 44.2      |\n",
      "|    critic_loss     | 0.0485    |\n",
      "|    ent_coef        | 0.173     |\n",
      "|    ent_coef_loss   | -0.271    |\n",
      "|    learning_rate   | 0.0006    |\n",
      "|    n_updates       | 3899      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -956     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 116      |\n",
      "|    total_timesteps | 4800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 40.3     |\n",
      "|    critic_loss     | 0.0399   |\n",
      "|    ent_coef        | 0.144    |\n",
      "|    ent_coef_loss   | -0.458   |\n",
      "|    learning_rate   | 0.0006   |\n",
      "|    n_updates       | 4699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -847     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 136      |\n",
      "|    total_timesteps | 5600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 40.6     |\n",
      "|    critic_loss     | 0.0542   |\n",
      "|    ent_coef        | 0.119    |\n",
      "|    ent_coef_loss   | 0.275    |\n",
      "|    learning_rate   | 0.0006   |\n",
      "|    n_updates       | 5499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -761     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 156      |\n",
      "|    total_timesteps | 6400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 35.4     |\n",
      "|    critic_loss     | 0.0375   |\n",
      "|    ent_coef        | 0.0975   |\n",
      "|    ent_coef_loss   | -0.22    |\n",
      "|    learning_rate   | 0.0006   |\n",
      "|    n_updates       | 6299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -688     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 176      |\n",
      "|    total_timesteps | 7200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 35.8     |\n",
      "|    critic_loss     | 0.0275   |\n",
      "|    ent_coef        | 0.0797   |\n",
      "|    ent_coef_loss   | -0.0909  |\n",
      "|    learning_rate   | 0.0006   |\n",
      "|    n_updates       | 7099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -632     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 196      |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 31.1     |\n",
      "|    critic_loss     | 0.0279   |\n",
      "|    ent_coef        | 0.0643   |\n",
      "|    ent_coef_loss   | -0.174   |\n",
      "|    learning_rate   | 0.0006   |\n",
      "|    n_updates       | 7899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -589     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 217      |\n",
      "|    total_timesteps | 8800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 27.1     |\n",
      "|    critic_loss     | 0.0264   |\n",
      "|    ent_coef        | 0.0502   |\n",
      "|    ent_coef_loss   | -0.662   |\n",
      "|    learning_rate   | 0.0006   |\n",
      "|    n_updates       | 8699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -554     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 237      |\n",
      "|    total_timesteps | 9600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 26.4     |\n",
      "|    critic_loss     | 0.0385   |\n",
      "|    ent_coef        | 0.0414   |\n",
      "|    ent_coef_loss   | -0.466   |\n",
      "|    learning_rate   | 0.0006   |\n",
      "|    n_updates       | 9499     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Modelos de SAC\n",
    "gamma = [0.95, 0.9]\n",
    "learning_rate = [3e-4, 6e-4,]\n",
    "max_mean_reward = float('-inf')\n",
    "\n",
    "for g in gamma:\n",
    "    for lr in learning_rate:\n",
    "        model = SAC(policy='MlpPolicy', env=env, seed=1, verbose=1, learning_rate=lr, gamma=g) # Defina o modelo\n",
    "        model.learn(total_timesteps= 1e4) # Treine o modelo\n",
    "        n_episodes = 20 # Defina o número de episódios\n",
    "        # Avaliando o agente e guardando o desempenho no dicionário\n",
    "        mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=n_episodes, deterministic=True)\n",
    "        if mean_reward > max_mean_reward:\n",
    "            max_mean_reward = mean_reward\n",
    "            max_std_reward = std_reward\n",
    "            opt_gamma = g\n",
    "            opt_lr = lr\n",
    "\n",
    "algorithms_dict['SAC teste'] = {'mean_reward': max_mean_reward, 'std_reward': max_std_reward}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de hiperparâmetros encontrado para o SAC\n",
      "gamma obtido: 0.95\n",
      "learning_rate obtido: 0.0003\n"
     ]
    }
   ],
   "source": [
    "print(f'Melhor conjunto de hiperparâmetros encontrado para o SAC\\ngamma obtido: {opt_gamma}')\n",
    "print(f'learning_rate obtido: {opt_lr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, detalhe um pouco mais quais foram os algoritmos testados bem como a performance obtida por cada um.\n",
    "\n",
    "Este detalhamento pode ser feito por meio de um ou mais gráficos mostrando o desempenho dos modelos, ou simplesmente por texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TD3 ideal': {'mean_reward': -147.04256373576936,\n",
       "  'std_reward': 114.15893494822676},\n",
       " 'SAC ideal': {'mean_reward': -137.0330131453462,\n",
       "  'std_reward': 98.30879141029631},\n",
       " 'TD3 teste': {'mean_reward': -393.7203647630289,\n",
       "  'std_reward': 100.32272172196895},\n",
       " 'SAC teste': {'mean_reward': -155.9544133479707,\n",
       "  'std_reward': 78.92418941143069}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Espaço para o Piloto criar gráficos ou textos para mostrar os diferentes resultados entre modelos\n",
    "algorithms_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha do Algoritmo\n",
    "\n",
    "Após testar e analisar diversos algoritmos diferentes, qual foi o escolhido?\n",
    "\n",
    "_Pergunta Extra:_ você usou algum critério para escolher quais algoritmos seriam testados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando os resultados obtidos, a escolha mais adequada é do `SAC`, visto que foi o algoritmo que teve a maior recompensa média, tanto dentre os modelos considerados ideais, quanto para os modelos que foram formulados e tunados aqui."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('main')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "216ea0e26501513bad6154ccdacf0692f26a477fdf468656248cfa466ee965b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
